---
layout: post
title: Понятия (глоссарий) SPSS
comments: true
category: stat
tags: SPSS
---

- **$$ B $$**. Показатели **$$ B $$** представляют собой набор коэффициентов и константу регрессионного уравнения. Показатель **$$ B $$** можно рассматривать как весовой коэффициент, характеризующий влияние соответствующей независимой переменной (предиктора) на зависимую переменную (критерий). Положительное значение **$$ B $$** указывает на то, что с возрастанием предиктора значение критерия возрастает, а отрицательное значение **$$ B $$** — на то, что значение критерия убывает.

- **df** - Число степеней свободы.
- **F-критерий**. В дисперсионном анализе отношение межгруппового среднего квадрата к внутригрупповому среднему квадрату. Данная величина позволяет сравнить межгрупповую дисперсию с внутригрупповой дисперсией. В случае если первая окажется значительно выше второй, это будет означать наличие значимого различия между группами. В множественном регрессионном анализе **F-критерий** позволяет определить значимость множественной корреляции.
- **K**. В иерархической логлинейной модели, порядок взаимодействия эффектов; $$ k = 1 $$ соответствует первому порядку (одна переменная), $$ k = 2 $$ — второму порядку (две переменные), и т. д.
- **R**. Множественный коэффициент корреляции между зависимой переменной и двумя или более независимыми переменными. Значение R лежит в пределах от 0 до 1 и интерпретируется по аналогии с обычным (двухмерным) коэффициентом корреляции.
- **$$ R^{2} $$**. Квадрат коэффициента множественной корреляции (коэффици- ент детерминации), доля дисперсии зависимой переменной, обусловленная воздействием двух или более независимых переменных.
- **S-стресс**. В многомерном шкалировании мера степени соответствия модели исходной матрице различий. Чем меньше это значение, тем лучше соответствие.
- **t-критерий**. Критерий для определения статистической значимости различия двух средних.
- **t-критерий для зависимых выборок**. Критерий, сравнивающий средние значения двух распределений для одной и той же выборки.
- **t-критерий для независимых выборок**. Критерий, сравнивающий средние значения одной и той же переменной для двух независимых выборок.
- **t-критерий для одной выборки**. Критерий, предназначенный для сравнения среднего значения распределения переменной с некоторой эталонной величиной.
- **t-критерий в регрессионном анализе**. Критерий, определяющий статистическую значимость корреляций, равен отношению коэффициента **B** к своей стандартной ошибке.
- **V-Крамера**. Мера ассоциации между значениями двух категориальных переменных. Значение **V** всегда варьируется от 0 до 1 и интерпретируется по аналогии с коэффициентом корреляции (исключая отсутствия отрицательных значений). Нередко используется в контексте $$ \chi^{2} $$-анализа; вычисление осуществляется по формуле (k — наименьшее из количеств строк и столбцов):

$$ V=\sqrt{\chi^{2}/N(k-1)} $$

- **z-значения**. Также называются стандартизованными значениями. После стандартизации (или z-преобразования) значений переменной среднее равно 0, стан- дартное отклонение равно 1. Стандартизованное значение может характеризовать направление и степень отклонения исходного значения от среднего. Для стандартизованных значений, превышающих по модулю 1,96, уровень значимости оказывается ниже 0,05.
- **Альфа ($$ \alpha $$)**. Мера внутренней согласованности измерительной шкалы, вычисляемая по формуле $$ \alpha = rk/[1 + (k – 1)r] $$, где k — число переменных в анализе, r — среднее значение корреляции между пунктами шкалы. Значение α зависит от числа переменных, поэтому нет точной интерпретации его величины; тем не менее, в большинстве случаев действует следующая оценка внутренней согласованности шкалы: α > 0,9 — отличная; α > 0,8 — хорошая; α > 0,7 — приемлемая; α > 0,6 — со- мнительная; α > 0,5 — малопригодная; α < 0,5 — недопустимая.
- **Альфа**, если элемент удален. В анализе надежности значение **$$ \alpha $$** для шкалы, получающейся путем удаления текущего ее пункта.
- **Априорная вероятность для каждой группы**. Вероятность, характеризующая предполагаемое соотношение численности групп. Для каждой из двух групп она равна 0,5, если предполагается, что их численность одинакова.
- **Асимметричная матрица**. Квадратная матрица, у которой хотя бы в одной паре ячеек, симметрично расположенных относительно главной диагонали, значения различны. Примером симметричной матрицы является корреляционная матрица.
- Асимметрия. Мера отклонения распределения от нормального, характеризующая симметричность графика.
- Асимптотические значения. Величины, на которых основано определение оценок параметров. Оценки параметров вычисляются в случаях, когда определение точных значений невозможно, в частности, в регрессионном анализе и некоторых других статистических процедурах.
- Барлетта критерий сферичности. Критерий многомерной нормальности для рас- пределения переменных. Помимо нормальности критерий проверяет, отличаются ли корреляции от 0. Значение p-уровня, меньшее 0,05, указывает на то, что данные вполне приемлемы для проведения факторного анализа
- Бета (β). В регрессионном анализе β означает стандартизованный коэффициент регрессии и представляет собой B-коэффициент для нормализованных перемен- ных. Значения β всегда лежат в интервале от –1 до +1 и могут сравниваться друг с другом для разных переменных.
- Бета при включении. Данная величина используется во множественном регрес- сионном анализе для переменных, не вошедших в уравнение регрессии, и пред- ставляет собой значение коэффициента β, рассчитанного в предположении, что соответствующая переменная была включена в регрессионное уравнение.
- Биномиальный критерий. Непараметрический критерий, определяющий степень близости эмпирического распределения бинарной переменной к биномиальному распределению, для которого частоты двух категорий равны.
- Бонферрони критерий. Критерий для множественного сравнения средних, если в дисперсионном анализе получен значимый результат.
- Вальда критерий. В модели логистической регрессии критерий значимости ко- эффициента B для соответствующего предиктора. Чем выше его значение (вместе с числом степеней свободы), тем выше значимость.
- Вероятность. Ожидаемая относительная частота некоторого события.
- Взаимодействие. Эффект совместного влияния на зависимую переменную двух и более независимых переменных, который не сводится к их раздельному влиянию. В случае двух независимых переменных проявляется в том, что эффект влияния одной из них проявляется по-разному на разных уровнях другой переменной.
- Внутригрупповая сумма квадратов. Сумма квадратов отклонений наблюдаемых значений от среднего для каждой группы.
- Внутригрупповой фактор. Фактор, уровням которого соответствуют повторные измерения (зависимые выборки).
- Внутригрупповой эффект. Эффект внутригруппового фактора, уровням которого соответствуют повторные измерения (зависимые выборки).
- Вращение. Процедура, применяемая в факторном анализе для того, чтобы полу- чить более простую структуру факторов.
- Выборка. Подмножество объектов из некоторой генеральной совокупности, вы- бранное для статистических выводов относительно свойств всей совокупности.
- Гистограмма. Столбиковая диаграмма для отображения распределения частот по категориям (диапазонам значений) переменной. Горизонтальная ось графика соот- ветствует значениям переменной, а вертикальная — частотам.

Главный эффект. Воздействие независимой переменной на зависимую перемен-
ную. Примеры главных эффектов можно найти в главах 14 и 15.
График собственных значений. Диаграмма, позволяющая выбрать число факто- ров в факторном анализе на основе критерия каменистой осыпи Р. Кеттелла.
Гуттмана критерий половинного расщепления. В анализе надежности половинно- го расщепления значение надежности, полученное с помощью процедуры нижних пределов.
Дендограмма. Диаграмма древовидной структуры, иллюстрирующая процесс кла- стеризации в кластерном анализе. Пример дендограммы приведен в главе 21
Детерминант ковариационно-дисперсионной матрицы. Величина, характеризую- щая степень зависимости между значениями переменных. Чем меньше значение детерминанта, тем сильнее соответствующая зависимость. Эта величина использу- ется при вычислении М Бокса. Детерминант общей дисперсионно-ковариационной матрицы учитывает все матрицы, используемые в анализе.
Диаграмма рассеяния. График для анализа связи между двумя переменными, на котором каждый объект представляет собой точку. Положение точки задано парой значений двух переменных для данного объекта. Более подробное описание при- ведено в главе 9.
Диаграмма регрессии. Диаграмма разброса, включающая сдвиги точек от линии регрессии по вертикальной оси.
Дискриминантный анализ. Процедура создания формулы регрессии, на основе ко- торой производится разбиение объектов на группы, соответствующие категориям зависимой переменной.
Дисперсионный анализ (ANOVA). Статистический анализ, устанавливающий статистическую значимость различий между средними значениями для трех или более выборок.
Дисперсии пунктов. Аналог средних значений элементов (пунктов шкалы) в ана- лизе надежности. Поясняющий пример приведен в разделе «Представление ре- зультатов» главы 19.
Дисперсия. Характеристика выборочного распределения переменной, описываю- щая разброс значений вокруг среднего и вычисляемая как отношение суммы ква- дратов отклонений к объему выборки, уменьшенному на 1. Кроме того, дисперсия представляет собой квадрат стандартного отклонения.
Дисперсия шкалы, если элемент удален. Дисперсия суммы всех пунктов шкалы, кроме удаленного пункта.
Доверительный интервал. Диапазон, в котором находится большинство значений выборки. Например, термин «доверительный интервал в 95 %» означает интервал, в который любое случайное значение из выборки попадает с вероятностью 95 %.
Доверительный интервал в 95 %. См. Доверительный интервал.
Знаков критерий. Непараметрический критерий, определяющий различие двух измерений для одной выборки на основе знаков разностей пар значений.
Значимость (p-уровень). Мера случайности полученного результата, равная ве- роятности того, что в генеральной совокупности этот результат (различия, связь) отсутствует. Чем меньше эта вероятность (значение p-уровня), тем выше стати- стическая значимость результата. Результат считается статистически достоверным (значимым), если p-уровень не превышает 0,05.
Изменение R2. Изменение величины R2 в результате введения новой переменной в уравнение регрессии.
Исправленная величина R2. Во множественном регрессионном анализе величина R2 является точной для выборок, однако в генеральной совокупности ее значе- ние лишь приблизительно. Исправленная величина R2 представляет собой более точную оценку R2 для генеральной совокупности и используется при сравнениях моделей, содержащих различное число независимых переменных.
Итерация. Стадия процесса формирования регрессионного (дискриминантного) уравнения, на которой происходит включение или исключение очередной пере- менной. Процесс продолжается до тех пор, пока не перестанет удовлетворяться заданный в процедуре критерий.
Кайзера–Мейера–Олкина критерий адекватности выборки. Величина, характе- ризующая степень применимости факторного анализа к данной выборке. Правило интерпретации этого критерия следующее: более 0,9 — безусловная адекватность; более 0,8 — высокая адекватность; более 0,7 — приемлемая адекватность; более 0,6 — удовлетворительная адекватность; более 0,5 — низкая адекватность; менее 0,5 — факторный анализ неприменим к выборке.
Канонические дискриминантные функции. Одно или более линейное дискри- минантное уравнение, построенное таким образом, что классификация объектов по уровням зависимой переменной происходит наиболее точно. Более подробное описание вы можете найти в главе 22.
Канонические коэффициенты. В дискриминантном анализе канонический ко- эффициент представляет собой корреляцию между оценками дискриминантной функции и уровнями зависимой переменной. Более подробное описание вы може- те найти в главе 22.
Категориальная (номинальная) переменная. Переменная, каждое значение ко- торой указывает на принадлежность объекта к определенной группе (категории). Категориальная переменная не является количественной; она разделяет все объ- екты на непересекающиеся группы по определенному признаку (пол, хобби, класс и пр.), но не позволяет сравнивать объекты по уровню выраженности этого при- знака.
Квадрат евклидового расстояния. Мера, используемая по умолчанию в кластер- ном анализе для определения расстояния между объектами и кластерами и вы-числяемая как сумма квадратов разностей между значениями переменных двух объектов.
Квадрат эта (η2). Доля дисперсии зависимой переменной, обусловленная воздей- ствием со стороны независимой переменной. Так, η2 = 0,044 означает, что 4,4 % дисперсии зависимой переменной обусловлено данной независимой переменной.
Квадратная матрица. Матрица, строки и столбцы которой соответствуют одной и той же последовательности элементов (переменных или объектов).
Квартили. 25-й, 50-й и 75-й процентили.
Кластерный анализ. Процедура, на основе заданного правила объединяющая объекты или переменные в группы, называемые кластерами.
Ковариата. Количественная переменная, имеющая значительную корреляцию с зависимой переменной и включаемая в анализ для более точной проверки воз- действий факторов на зависимую переменную.
Количественная переменная. Значения количественной переменной (в отличие от категориальной) отражают уровень выраженности у объектов соответствующе- го признака в метрической или порядковой шкале.
Колмогорова–Смирнова критерий для одной выборки. Непараметрический кри- терий, определяющий, отличается ли данное эмпирическое распределение от тео- ретического распределения (нормального, равномерного, Пуассона или экспонен- циального).
Контрасты. Метод контрастов — это метод множественного сравнения средних в дисперсионном анализе, который позволяет сравнивать выборки по градациям независимой переменной. Например, контрасты позволяет сравнивать одну града- цию с другой, одну градацию со всеми остальными или разбить все градации на две группы и затем сравнить их между собой.
Корреляция. Мера степени и направления связи между значениями двух пере- менных. Понятию корреляции посвящена глава 9.
Корреляция между формами. В анализе надежности половинного расщепления приближенное значение надежности измерения в предположении, что обе полови- ны содержат одинаковое число пунктов.
Корреляция между элементами. В анализе надежности это описательная инфор- мация о корреляциях каждого пункта с суммой всех остальных пунктов.
Коэффициент корреляции. Мера связи двух переменных, обозначаемая симво- лом r и принимающая значения от –1 до +1.
Коэффициенты регрессии. B-коэффициенты, то есть множители при переменных, входящих в состав регрессионного уравнения, а также константа.
Критерий согласия. В логлинейном анализе критерий χ2 для определения степени адекватности модели исходным данным. Чем выше его значения и чем ниже соот- ветствующие уровни значимости, тем хуже модель соответствует данным.
Ливиня критерий. Критерий, предназначенный для проверки гипотезы о том, что все распределения зависимой переменной для сравниваемых выборок имеют оди- наковые дисперсии.
Линия регрессии. Линия на графике двухмерного рассеяния, отражающая наибо- лее точные прогнозируемые значения («линия наилучшего соответствия»).
Логарифмический детерминант. В дискриминантном анализе натуральный лога- рифм определителя каждой ковариационной матрицы. Логарифмический детер- минант используется для вычисления М Бокса.
Логит. Натуральный логарифм шанса. Описание понятия «логит» приводится в главе 24.
Лямбда Уилкса. Отношение внутригрупповой суммы квадратов к общей сумме квадратов, характеризующее дисперсию оценок дискриминантной функции, не обусловленную различиями между двумя группами. Единичное значение лямбда принимает в случае, если наблюдаемые средние значения групп равны; значения, близкие к нулю, означают, что внутригрупповая дисперсия мала по сравнению с общей дисперсией.
М Бокса (M). Критерий равенства дисперсионно-ковариационных матриц, осно- ванный на близости значений определителей матриц ковариаций двух или более групп. Аналог критерия Ливина для многомерного случая.
Максимум. Наибольшее наблюдаемое значение распределения переменной. Манна–Уитни и Уилкоксона критерий ранговых сумм. Непараметрический аналог
t-критерия, определяющий различие между двумя выборками на основе рангов. Матрица различий. Матрица, каждое значение которой соответствует различию между двумя объектами.
Матрица трансформации факторов. Результатом умножения этой матрицы и ма- трицы факторных нагрузок до вращения является матрица нагрузок факторов по- сле вращения.
Медиана. Значение переменной, делящее упорядоченное множество всех значе- ний выборки ровно пополам: у половины объектов выборки значения переменной больше, а у другой половины меньше медианы.
Медианный критерий k выборок. Непараметрический критерий для сравнения двух и более выборок по уровню выраженности признака; основан на подсчете числа элементов, лежащих выше и ниже главной медианы.
Межгрупповая сумма квадратов. Сумма квадратов разностей между главным средним значением и средними значениями групп, умноженных на весовые коэф- фициенты, равные числу объектов в соответствующих группах.
Метод главных компонент. Метод, применяемый SPSS по умолчанию в фактор- ном анализе для извлечения факторов.
Метод иерархического слияния. Метод, используемый в кластерном анализе, при выполнении которого объекты объединяются в кластеры по одному на каждом шаге до тех пор, пока не будет образован единственный кластер, охватывающий все объекты. Кластерный анализ подробно описан в главе 21.
Метрическая переменная. Количественная переменная, соответствующая изме- рению признака в шкале интервалов или отношений. В отличие от ранговой (по- рядковой) переменной, при сравнении объектов позволяет судить не только о том, больше или меньше выражен признак, но и о том, насколько больше (меньше) он выражен.
Минимум. Наименьшее наблюдаемое значение распределения переменной.
Многомерные критерии значимости. В многомерном дисперсионном анализе на- бор критериев, позволяющих определить влияние факторов и их взаимодействий на совокупность зависимых переменных. Наиболее мощным считается критерий Пилая.
Многомерный дисперсионный анализ (ОЛМ-многомерная, MANOVA). Отли- чие многомерного дисперсионного анализа от одномерного (ANOVA) заключается в том, что число зависимых переменных в нем может быть теоретически любым.
Многомерный ковариационный анализ (MANCOVA). Многомерный дисперсион- ный анализ с включением в анализ ковариат.
Многомерный дисперсионный анализ с повторными измерениями (ОЛМ- повторные измерения). Вид дисперсионного анализа, в котором одна и та же группа объектов подвергается действию каждого уровня независимой переменной. С точки зрения вычислений этот анализ можно назвать внутригрупповым.
Многомерный критерий однородности матриц ковариаций. Критерий М Бокса определяет, являются ли ковариационные матрицы одинаковыми. Для каждого из значений вычисляется p-уровень, а также величина F или χ2.
Многомерное шкалирование. Метод, позволяющий на основе матрицы различий между объектами построить одно-, двух- или трехмерное изображение, иллюстри- рующее удаленность этих объектов друг от друга.
Множественный регрессионный анализ. Метод, позволяющий спрогнозировать значения зависимой переменной на основе известных значений независимых пере- менных.
Мода. Наиболее часто повторяющееся значение распределения переменной.
Моучли критерий сферичности. Критерий многомерной нормальности. SPSS вы- числяет приблизительное значение χ2 и соответствующий уровень значимости. Если уровень значимости оказывается менее 0,05, то, вероятно, данные не являют- ся нормально распределенными.
Наблюдаемое значение или частота. В χ2-анализе фактическая частота катего- рии.
Надежность половинного расщепления. Мера надежности, для вычисления ко- торой все пункты шкалы делятся на две эквивалентные группы, а затем на основе корреляции между двумя половинами шкалы устанавливается ее внутренняя со- гласованность.
Наименьшая ожидаемая частота. Наименьшая частота в ячейке таблицы сопря- женности, определяемая в процессе применения критерия χ2.
Наименьшей значимой разности критерий (НЗР). Критерий множественного сравнения средних, представляющий собой серию t-критериев; применяется, если в дисперсионном анализе получен значимый результат.
Накопленная частота. Суммарное число объектов, имеющих значение перемен- ной, не большее, чем указано.
Накопленный процент. Процент объектов от общего числа, имеющих значение переменной, не большее, чем указано.
Насыщенная модель. Логлинейная модель, включающая все взаимодействия и главные эффекты факторов.
Нелинейная регрессия. Процедура вычисления параметров нелинейного регрес- сионного уравнения.
Неортогональное вращение. Процедура, используемая в факторном анализе, до- пускающая результат, в котором угол между факторами отклоняется от прямого. Это иногда желательно для достижения более простой структуры.
Непараметрические критерии. Серия критериев, каждый из которых применяет- ся без предварительных допущений относительно нормальности распределения. Непараметрические критерии основаны на ранжировании, попарных сравнениях и других средствах, не требующих нормальности распределения переменных.
Нестандартизованные коэффициенты канонической дискриминантной функции.
Список коэффициентов и константа дискриминантного уравнения.
Номинальная шкала. См. Категориальная переменная
Нормальное распределение. Распределение частот (вероятностей), графически представляемое в виде симметричной кривой, имеющей пик в центре и асимпто- тически приближающееся к горизонтальной оси по краям. Идеальное нормальное распределение характеризуется нулевыми значениями асимметрии и эксцесса.
Общая внутригрупповая ковариационная матрица. Матрица, состоящая из сред- них значений ковариационных матриц, вычисленных для каждого уровня зависи- мой переменной.
Общая сумма квадратов. Сумма квадратов отклонений всех значений от среднего значения всего распределения.
Общность. В факторном анализе мера, характеризующая долю дисперсии пере- менной, обусловленную воздействием всех факторов.
Одномерные F-критерии. В многомерном дисперсионном анализе критерии, ко- торые характеризуют влияние независимых переменных и их взаимодействий на каждую зависимую переменную в отдельности.
Ожидаемое значение. В перекрестной таблице при использовании критерия χ2 значение, вычисляемое в предположении, что все переменные являются полно- стью независимыми друг от друга. В регрессионном анализе термин «ожидаемое значение» эквивалентен термину «прогнозируемое значение» и означает величину, получаемую для каждого объекта в результате подстановки значений переменных для него в уравнение регрессии.
Остатки и стандартизованные остатки. В логлинейных моделях остатки пред- ставляют собой разности между ожидаемыми и наблюдаемыми частотами. Чем выше значения остатков, тем менее адекватной является модель. SPSS подсчи- тывает исправленные величины остатков с использованием оценок стандартного отклонения. Исправленные остатки представлены в единицах нормального рас- пределения, и, как правило, значения остатков, по модулю превышающие 1,96, являются значимыми.
Остаток. Как правило, разность между наблюдаемым и ожидаемым значениями. Эта величина относится к части дисперсии, которая не объясняется воздействием независимых переменных.
Отклонение. Расстояние и направление (отрицательное или положительное) меж- ду средним и данным значениями.
Оценка дискриминантной функции. Значение, получаемое для каждого объекта путем подстановки значений его переменных в уравнение дискриминантной функ- ции.
Параметр. Некоторая числовая характеристика генеральной совокупности. Параметрические критерии. Критерии, применяемые в предположении о нор-
мальном распределении переменных в генеральной совокупности.
Переменные в уравнении. При выводе результатов пошагового регрессионного анализа SPSS включает для каждого шага статистики тех переменных, которые вошли в уравнение регрессии.
Пирсона коэффициент корреляции. Мера корреляции, идеально подходящая для двух непрерывных (метрических) переменных.
Порядковая (ранговая) шкала. См. Ранговая переменная.
Прямоугольная матрица. Матрица, для которой строкам и столбцам соответствуют разные последовательности элементов (объектов или переменных).
Размах. Характеристика распределения, равная разности между минимумом и максимумом распределения.
Ранговая (порядковая) переменная. Количественная переменная, отражающая измеренное качество на уровне порядка: в большей или меньшей степени оно вы-ражено. В отличие от метрической шкалы, не позволяет судить о том, насколько больше или меньше выражено качество, поэтому не допускает применение ариф- метических операций.
Распределение. Статистическое понятие, обозначающее соотношение значений признака и частот (вероятностей) их встречаемости. Распределение (вероятно- стей, частот) может быть представлено в виде формулы для функции распределе- ния вероятностей, графика распределения частот (гистограммы, столбиковой диа- граммы), таблицы распределения частот.
Регрессионный анализ. Инструмент статистики, позволяющий прогнозировать значения зависимой переменной с помощью известных значений независимых переменных. Подробное рассмотрение регрессионного анализа проводится в гла- вах 17 и 18.
Регрессия. В множественном регрессионном анализе этим термином обозначается статистика, отражающая влияние предикторов на зависимую переменную.
Серий критерий. Непараметрический критерий, определяющий, является ли по- следовательность бинарных величин (событий) случайной или упорядоченной.
Симметричная матрица. Квадратная матрица, для которой в каждой паре ячеек, расположенных симметрично относительно главной диагонали, содержатся оди- наковые значения. Типичным примером симметричной матрицы является корре- ляционная матрица.
Скорректированная корреляция пункта и суммы. В анализе надежности корреля- ция между пунктом шкалы и суммой всех остальных пунктов.
Собственное значение. В факторном анализе эта величина пропорциональна доле дисперсии, обусловленной влиянием данного фактора; в дискриминантном анализе отношение межгрупповой суммы квадратов к внутригрупповой сумме квадратов. Чем больше собственное значение, тем выше точность дискриминантной функции.
Спирмена–Брауна критерий неэквивалентных форм. В анализе надежности по- ловинного расщепления надежность, вычисленная для случая, когда «половины» имеют неравный размер.
Спирмена–Брауна критерий эквивалентных форм. Используется в анализе на- дежности, когда число элементов в «половинах» одинаково (вычисляется коэффи- циент корреляции).
Среднее шкалы при удалении пункта. В анализе надежности для каждого пункта шкалы вычисляется сумма остальных пунктов по всем объектам выборки; отно- шение указанной суммы к числу объектов является средним шкалы, если данный элемент удален.
Средние значения пунктов. В анализе надежности (с применением альфа Крон- баха) описательная информация, касающаяся средних значений пунктов шкалы по всем наблюдениям. Поясняющий пример приведен в разделе «Представление результатов» главы 19.
Средний квадрат. Отношение суммы квадратов к числу степеней свободы. В одно- факторном дисперсионном анализе, как правило, средний квадрат вычисляется для внутригрупповой и межгрупповой сумм квадратов, а в регрессионном ана- лизе — для регрессионной и остаточной сумм квадратов. Во всех перечисленных случаях средний квадрат используется для вычисления F-критерия.
Стандартизованный коэффициент α. В анализе надежности значение α, получен- ное в случае, если перед проведением анализа стандартизовать распределения всех элементов шкалы.
Стандартная ошибка. Стандартное отклонение величины, получаемое в результа- те ее многократного вычисления для случайных выборок. Как правило, стандарт- ная ошибка вычисляется для среднего значения распределения.
Стандартное отклонение. Мера разброса значений распределения вокруг среднего. Стандартное отклонение определяется как квадратный корень дисперсии (суммы квадратов отклонений от среднего, деленной на N – 1, где N — объем выборки).
Статистики шкалы. В анализе надежности статистические характеристики суммы всех переменных по объектам.
Столбиковая диаграмма. График распределения частот по категориям (значе- ниям) переменной. Каждый столбец на графике соответствует одному значению признака, а его высота пропорциональна частоте встречаемости этого значения. Аналогичное средство для количественных переменных, имеющих большое число возможных значений, обычно называется гистограммой.
Стресс. В многомерном шкалировании мера соответствия модели исходной ма- трице различий. Чем меньше значение стресса, тем лучше соответствие модели.
Сумма квадратов. Стандартная мера разброса, представляющая собой сумму ква- дратов отклонений всех значений величины от среднего.
Таблица распределения (частот). Таблица, устанавливающая соотношение между категориями (значениями) признака и частотами их встречаемости.
Таблица сопряженности (кросстабуляции). Обычно таблица совместного рас- пределения частот для двух категориальных или дискретных переменных; строки соответствуют категориям (значениям) одной, а столбцы — другой переменной. Подробно таблицы сопряженности описаны в главе 8.
Толерантность. Мера линейной зависимости между одной переменной и набором других переменных. Если при дискриминантном анализе уровень толерантности составляет менее 0,001, это означает, что линейная зависимость для данной пере- менной настолько высока, что ее включение в дискриминантное уравнение недо- пустимо.
Тьюки критерий подлинной значимости. Критерий множественного сравнения, позволяющий попарно сравнивать средние значения; применяется, если дисперси- онный анализ показал значимый результат.
Уилкоксона критерий. Непараметрический критерий, сходный критерием знаков, однако в отличие от последнего использующий ранги положительных и отрица- тельных разностей.
Фактор. В факторном анализе объединение нескольких переменных, чья взаим- ная корреляция исчерпывает определенную долю общей дисперсии. После проце- дуры вращения каждый фактор интерпретируется как некоторая общая причина взаимосвязи группы переменных.
Факторный анализ. Метод, позволяющий свести большое количество исходных переменных к значительно меньшему числу факторов, каждый из которых объеди- няет исходные переменные, имеющие сходный смысл.
Фи (φ). Мера связи (корреляции) двух категориальных переменных, обычно при- меняемая наряду с критерием χ2 при анализе таблиц сопряженности и вычисляемая по формуле: $$ \phi=\sqrt{\chi^{2}/N} $$
Фридмана дисперсионный анализ. Непараметрическая процедура, определяю- щая, различаются ли между собой три или более измерения для одной и той же выборки, на основе среднего ранга каждого измерения.
Хи-квадрат (χ2) для модели. В анализе логистической регрессии величина, позво- ляющая определить, оказывают ли переменные, входящие в состав регрессионного уравнения, значимое влияние на зависимую переменную. Чем выше полученное значение, тем значительнее воздействие.
Хи-квадрат (χ2) критерий для одной выборки. Непараметрический критерий, определяющий отличие наблюдаемого распределения переменной от ожидаемого (теоретического) распределения.
Хи-квадрат критерий (критерий χ2). Непараметрический критерий для сравне- ния ожидаемых и наблюдаемых частот (как правило, для таблиц сопряженности). Критерий χ2 может использоваться для оценки адекватности структурных и ло- глинейных моделей. В любом случае, χ2-анализ всегда отвечает на один и тот же вопрос: отличаются ли ожидаемые частоты модели от наблюдаемых. Коэффициент χ2 Пирсона вычисляется по следующей формуле:

!! Формула !! 

Центроиды групп. В дискриминантном анализе средние значения дискриминант- ных функций для каждой из двух или более групп. Если число групп равно 2, центроиды будут иметь одинаковые абсолютные величины и разные знаки. Чем ближе объект в центроиду группы, тем больше вероятность, что он принадлежит к этой группе.
Частичный критерий χ2. Значение критерия χ2, характеризующее долю воздей- ствия очередной независимой переменной на зависимую переменную.

Частота (абсолютная). Количество объектов в выборке, имеющих данное значе-
ние признака.
Частота относительная. Доля объектов в выборке, имеющих данное значение при- знака; равна отношению абсолютной частоты к объему выборки.
Число степеней свободы (df). Количество возможных направлений изменчивости статистического показателя, наряду с эмпирическим значением критерия служит для определения p-уровня значимости.
Шаговый отбор переменных. Процедура, включающая и исключающая перемен- ные из дискриминантного или регрессионного уравнения в соответствии с вы- бранными критериями.
Шанс. Отношение вероятности того, что событие произойдет, к вероятности того, что событие не произойдет.
Шеффе критерий. Процедура, позволяющая осуществлять попарные множествен- ные сравнения средних значений после получения статистически достоверного результата дисперсионного анализа.
Экспонента B. В логистическом регрессионном анализе величина eB используется в одной из форм регрессионного уравнения и позволяет создать одну из интерпре- таций коэффициентов регрессии.
Эксцесс. Мера «сглаженности» («островершинности» или «плосковершинности») распределения. Если значение эксцесса близко к 0, это означает, что форма рас- пределения близка к нормальному виду. Детальное описание эксцесса приведено в главе 7.
Эта (η). Мера корреляции между двумя переменными в случае, если одна из них является категориальной.