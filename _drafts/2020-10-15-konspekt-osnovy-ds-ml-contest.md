---
layout: post
title: Конспект курса основы Data Science. ML contest
comments: true
category: ML/DS
tags: python ds
---

<meta name="robots" content="noindex" />

Практическим проектом нашего курса будет анализ активности студентов онлайн курса Введение в анализ данных в R, спасибо команде stepik, что предоставили анонимизированные данные.

В этом модуле, мы разберемся с задачей, начнем исследовать данные, а об условиях соревнований, призах и тайных стэпах раскажу во втором модуле!

Описание данных:

[events_train.csv](https://stepik.org/media/attachments/course/4852/event_data_train.zip) - данные о действиях, которые совершают студенты со стэпами

- **step_id** - id стэпа
- **user_id** - анонимизированный id юзера
- **timestamp** - время наступления события в формате unix date
- **action** - событие, возможные значения: 
- **discovered** - пользователь перешел на стэп
- **viewed** - просмотр шага,
- **started_attempt** - начало попытки решить шаг, ранее нужно было явно нажать на кнопку - начать решение, перед тем как приступить к решению практического шага
- **passed** - удачное решение практического шага

[submissions_train.csv](https://stepik.org/media/attachments/course/4852/submissions_data_train.zip) - данные о времени и статусах сабмитов к практическим заданиям

- **step_id** - id стэпа
- **timestamp** - время отправки решения в формате unix date
- **submission_status** - статус решения
- **user_id** - анонимизированный id юзера

Немного интро. Очень обобщенно, у нас есть курс и его часть людей не прохдит до конца. Необходимо понять, где люди отваливаются, как можно исправить существующий курс, чтобы было ОК, не менняя радикально структуру. Задачу можно представи ть как задачу классификации, где 1-й класс - люди, которые не закончили, 2-й - закончили. Если мы создадим классификатор, который научится предсказывать на начальных этапаха, закончит ли студент курс, то можно будет как-то направлять и стимулировать студента в нужный момент.

Тут займемся data preprocessing'ом. Будем обрабавывать сырые данные.

Хотим ответить на вопросы:
- почему пользователи не заканчивают курс до конца;
- как предсказать, что пользователь бросит курс;
- какими основными характеристиками и паттернами поведения взаимодействия с контентом обладают пользователи, которые заканчивают курс, по сравнению с теми, кто эти курсы бросают.

Первым делом у нас есть только данные. В первом датасете у нас данные по событиям, которые происходят на курсе, а во втором - данные про то, как пользователи пытаются сдать практическую задачу.

Сначала посмотрим на данные и узначем, что там вообще происходит.

```python
import pandas as pd
import numpy as np
%matplotlib inline
import matplotlib as plt
import seaborn as sns

event_data = pd.read_csv('.../ml_contest/event_data_train.csv')
event_data.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/1.png">

Данные у нас очень сырые. В данных у нас представлен ```user_id```, что он сделал - ```action``` (```viewed``` - просмотрел, ```discovered``` - , ```passed``` - сдал степ, ```started_attempt``` - начал решать практическую задачу), ```timestamp``` - секунды с 01.01.1970.

Нам нужно самим обработать данные для исследования, чтобы преобразовать его к знакомому виду DataFram'а, где будут строчки, коолнки, целевая переменная. И можно уже будет проверять гипотезы, строит модели и тп.

Самым первым делом нужно убедиться, что полученные данные вообще валидные, нормальные, изучить их.

```python
event_data.action.unique() # пользователь может "просмотреть степ", "решить", "впервые его увидеть", "начать решать".
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/2.png">

Нужно как-то преобразовать данные, чтобы можно было строить гипотезы и тп.

Сделаем базовую визуализацию, посмтроим за какой период эти данные, сколько польлзователей, что они делали, как и когда. Переведем timestampt в более читаемый вид, в дату, чтобы можно было отвечать на вопрос, сколько было уникальных пользователей в этом курсе, по месяцам. 


```python
event_data['date'] = pd.to_datetime(event_data.timestamp, unit='s')
event_data.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/3.png">

Чтобы проверить, нет ли проблем по времени можем посмотреть первый визит и последний в данных.

```python
event_data.date.max()
event_data.date.min()
```

- [Работы с датой в Pandas](https://medium.com/datadriveninvestor/how-to-work-with-dates-in-pandas-like-a-pro-a84055a4819d)
- [Второй вариант](https://www.geeksforgeeks.org/python-working-with-date-and-time-using-pandas/)

Добавим колонку с днем.

```python
event_data['day'] = event_data.date.dt.date
event_data.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/4.png">

Посмотрим сколько было уникальный пользователей по дню.

```python
event_data.groupby('day').user_id.nunique().head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/5.png">

```python
sns.set(rc={'figure.figsize': (9, 6)}) # Чтобы график был адекватный
event_data.groupby('day').user_id.nunique().plot()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/6.png">

С респределением уникальных пользователей по дням понятно. Посмотрим, как распределены данные пользоватлей по баллам, которые они набрали за курс. Просто дял каждого пользователя без учета даты его старта на курсе, посчитаем число пройденных степов и посмотрим на распределение.

```python
event_data.pivot_table(index='user_id',
    columns='action',
    values='step_id',
    aggfunc='count',
    fill_value=0).reset_index().discovered.hist()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/7.png">

Подрубим еще один источник данных. submissions_data. Тут есть юзер, степ_айди, статусы заданий (взаимодействие с контентом).

```python
submission_data = pd.read_csv('.../ml_contest/submissions_data_train.csv')
submission_data.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/8.png">

Для этих данных тоже сделаем дату нормальную.

```python
submission_data['date'] = pd.to_datetime(submission_data.timestamp, unit='s')
submission_data.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/9.png">

Сделаем pivot_table, с юзерами и количеством правильных/неправильных ответов.

```python
users_scores = submission_data.pivot_table(index='user_id',
    columns='submission_status',
    values='step_id',
    aggfunc='count',
    fill_value=0).reset_index()

users_scores.head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/10.png">

Таким образом, первым этапом смотрим какие-нибудь базовые штуки, чтобы понять, что данные вообще из себя представляют. Не потеряны ли там куски и тп., посмотреть описательные статистики.

Сделаем несколько базовых вещей для каждого пользователя:
- посчитаем кол-во уникальных степов, которые он прошел;
- сколько он отправил правильных сабмитов;
- сколько он отправил НЕправильных сабмитов;
- сколько уникальных дней он учился на степике.

И посмотрим, различаются ли эти показатели у пользователей, которые успешно закончили курс и пользователей, которые курс бросили.

**! Тут возникает важный нюанс и как мы ответим на этот вопрос, будет полностью влиять на то, какую задачу мы решаем и как:** Сказано было "пользователи курс бросили", важно уичтывать, что часть пользователей находится в процессе. Допустим, он зарегался на курс неделю назад, порешал два дня и на 5 дней пропал. Вопрос: является ли этот пользователь тем кто бросил курс и больше не пройдет, или он все-таки вернется еще. Или допустим пользователь 5 дней порешал, а потом на 25 дней пропал - что с ним делать? 

С теми кто получил сертификаты - понятно. А дальше возникает еще две важные категории: 1 - пользователи, которые в процессе и они вренуться зааканчивать курс, 2 - пользователи, которые не закончили курс и уже бросили. Этот вопрос для себя нужно как-то решить. По хорошему нужно этот оформить в стиле data driven, например, если пользователь не заходил на платформу больше, чем N дней, то с вероятностью 95% мы можем считать его дропнувшимся. Подготовим данные, чтобы получился размеченный датасет тех пользователей, которые закончили курс, те, кто дропнулись.

Теперь подойдем к теме. Мы хотим предсказывать тех пользователей, которые дропнулись с курса (не дорешали до конца и больше не вернулись). Допустим, человек не был на курсе 2 недели - этого достаточно, чтобы считать, что он не вернется? или это все-таки типичная стратегия прохождения курса. На этот вопрос лучше ответить исходя из данных: из какого-нибудь статистического анализа. 

Проанализируем данные. Мы можем применить следующую стратегию: для каждого пользователя рассчитать, какие у него были промежутки в перерывах между уникальными днями, когда он проходил курс. Далее посмотреть на эту картину в целом по всем пользователям. И принять какое-нибудь статистическое решение. Чтобы ответить на этот вопрос, используем ```events_data```. Мы посмотрим, как в среднем распределено распределение перерывов в решении курса у пользователей. И, исходя из этих данных, ответим на исходный вопрос: **какой временной промежуток отсутствия на курсе, можно считать пороговым, после которого будем относить пользователя к категории ушедших?**.

Для этого сделаем следующее: оставим нужные нам для анализа данные, а именно ```user_id```, ```day```, ```timestamp```. Нужно будет посмотреть для каждого пользователя, какие перерывы в днях наблюдаются в момент прохождения курса. В течение дня может быть много событий с разным ```timestamp```. Нам эту инфу хранить не нужно. Если человек, хотя бы один раз зашел на курс в этот день, будем считать его активным в этот день. Тут поможет метод ```drop_duplicates()```, чтобы не хранить одинаковые значения. 

```python
event_data[['user_id', 'day', 'timestamp']].drop_duplicates(subset=['user_id', 'day']) \
    .groupby('user_id')['timestamp'].apply(list).head()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/11.png">

Нам интересно, какие были перерывы между этими днями. Для этого модернизируем запрос и используем функцию ```np.diff - возвращает разницу между ближайшими элементами```

```python
gap_data = event_data[['user_id', 'day', 'timestamp']].drop_duplicates(subset=['user_id', 'day']) \
    .groupby('user_id')['timestamp'].apply(list).apply(np.diff).values # теперь для каждого юзера созранена разница между его заходами на курс 
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/12.png">


Нужно взять аррэй аррээев и свести его в один аррэй. ```np.concatenate```

```python
gap_data = pd.Series(np.concatenate(gap_data, axis=0)) # 0-по строкам
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/13.png">

Теперь у нас есть пандовская серия, в которой сохранены для каждого пользователя значения разницы между двумя заходами на курс. Преобразуем ее в разницу в днях.

```python
gap_data = pd.Series(np.concatenate(gap_data, axis=0))
gap_data = gap_data / (24 * 60 * 60)
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/14.png">

Построим гистограмму. немного пофильтровав от выбросов.

```python
gap_data[gap_data < 200].hist()
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/15.png">

Большая часть гэпов между двумя заходами укладывается в диапазон от нуля до 25 дней. Посчитаем эту цифру более точно. 

```python
gap_data.quantile(0.95) # 95-квантиль
```

<img src="/assets/img/2020-10-15-konspekt-osnovy-ds-ml-contest/16.png">

То есть только 5% пользователей возвращается на курс после перерыва в два месяца.

Возьмем как gap 30 дней. Будет у нас некая оценка между 90-м и 95-м перцентилем. И используем это значение, что эмпирически определить, какое время отсутствия на курсе для данного пользователя будем считать достаточным, чтобы отнести его в категорию ушедших.

Разметим наши данные по принципу того, являются ли пользователи уже дропнувшимися или нет. Важно помнить, что если пользователь 2 месяца на курсе уже не появлялся, но он его прошел, то он дропнувшимся не является. *Будет составное условие:*
- Если человек не дошел курс до конца, т.е. не получил сертификат и при этом больше 30-ти дней отсутствует на платформе будепм считать, что с курса он дропнулся. 


Как мы будем считать отвалившихся пользователей? ....